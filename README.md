# Efficient Open Domain Question Answering

> 2022

- Boosted Dense Retriever, in _NAACL_ 2022. [[Paper]](https://aclanthology.org/2022.naacl-main.226/) [[Code: DrBoost]](https://github.com/facebookresearch/drboost)

> 2021

- Training Adaptive Computation for Open-Domain Question Answering with Computational Constraints, in _ACL-IJCNLP_ 2021. [[Paper]](https://aclanthology.org/2021.acl-short.57/) [[Code: APE]](https://github.com/uclnlp/APE)  
- Efficient Passage Retrieval with Hashing for Open-domain Question Answering, in _ACL_ 2021. [[Paper]](https://arxiv.org/abs/2106.00882) [[Code: BPR]](https://github.com/studio-ousia/bpr)   
- Learning Dense Representations of Phrases at Scale, in _EMNLP_ 2021. [[Paper]](https://arxiv.org/abs/2109.08133) [[Code: DensePhrases]](https://github.com/princeton-nlp/DensePhrases)  
- End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering, in _NeurIPS_ 2021. [[Paper]](https://openreview.net/forum?id=5KWmB6JePx)) [[Code: EMDR2]](https://github.com/DevSinghSachan/emdr2)  
- Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering, in _EACL_ 2021. [[Paper]](https://aclanthology.org/2021.eacl-main.74/)  [[Code: FiD]](https://github.com/facebookresearch/FiD)   
- PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them, in _TACL_ 2021. [[Paper]](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00415/107615/PAQ-65-Million-Probably-Asked-Questions-and-What) [[Code: PAQ]](https://github.com/facebookresearch/PAQ)  
- R2-D2: A Modular Baseline for Open-Domain Question Answering, in _EMNLP_ 2021. [[Paper]](https://arxiv.org/abs/2109.03502) [[Code: R2-D2]](https://github.com/KNOT-FIT-BUT/R2-D2)  
- RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering, in _NAACL_ 2021. [[Paper]](https://aclanthology.org/2021.naacl-main.466/) [[Code: RocketQA]](https://github.com/PaddlePaddle/RocketQA)  
- UnitedQA: A Hybrid Approach for Open Domain Question Answering, in _ACL_ 2021. [[Paper]](https://aclanthology.org/2021.acl-long.240/) [[Code: UnitedQA]](https://github.com/microsoft/unitedQA)
- Generation-Augmented Retrieval for Open-Domain Question Answering, in _ACL_ 2021. [[Paper]](https://aclanthology.org/2021.acl-long.316/) [[Code: GAR]](https://github.com/morningmoni/GAR)  

> 2020

- Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval, in _arXiv_ 2020. [[Paper]](https://arxiv.org/pdf/2007.00808.pdf) [[Code: ANCE]](https://aka.ms/ance)  
- ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT, in _ACM SIGIR _2020. [[Paper]](https://dl.acm.org/doi/10.1145/3397271.3401075) [[Code: Colbert]](https://github.com/stanford-futuredata/ColBERT)  
- Dense Passage Retrieval for Open-Domain Question Answering, in _EMNLP_ 2020. [[Paper]](https://aclanthology.org/2020.emnlp-main.550/) [[Code: DPR]](https://github.com/facebookresearch/DPR)  
- Contextualized Sparse Representations for Real-Time Open-Domain Question Answering, in _ACL_ 2020. [[Paper]](https://arxiv.org/abs/1911.02896) [[Code: DenSPI+Sparc]](https://github.com/jhyuklee/sparc)  
- How Much Knowledge Can You Pack Into the Parameters of a Language Model? in _EMNLP_ 2020. [[Paper]](https://aclanthology.org/2020.emnlp-main.437/) [[Code: T5]](https://github.com/google-research/google-research/tree/master/t5_closed_book_qa)  

> 2019 
- Bert-serini:End-to-End Open-Domain Question Answering with BERTserini, in _NAACL_ 2019. [[Paper]](https://aclanthology.org/N19-4013/) [[Code: Bertserini]](https://github.com/castorini/bertserini)  
- Real-Time Open-Domain QA with Dense-Sparse Phrase Index, in _ACL_ 2019. [[Paper]](https://aclanthology.org/P19-1436/) [[Code: DenSPI]](https://github.com/seominjoon/denspi)  
- Latent Retrieval for Weakly Supervised Open Domain Question Answering, in _ACL_ 2019. [[Paper]](https://aclanthology.org/P19-1612/) [[Code: ORQA]](https://github.com/google-research/language/tree/master/language/orqa)  
- Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring, in _ArXiv_ 2019. [[Paper]](https://arxiv.org/abs/1905.01969) [[Code: Poly-encoders]](https://github.com/sfzhou5678/PolyEncoder)  

> 2018

> 2017
- Reading Wikipedia to Answer Open-Domain Questions, in _ACL_ 2017. [[Paper]](https://arxiv.org/abs/1704.00051) [[Code: DrQA]](https://github.com/facebookresearch/DrQA)  
